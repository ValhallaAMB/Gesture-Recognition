{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValhallaAMB/Gesture-Recognition/blob/main/custom_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yxwgG92tIwp"
      },
      "source": [
        "**NOTE:**\n",
        "You might have to run the first cell and then restart the session by pressing `Ctrl+m+.`, then re-run the cell. It should work after that"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-ApCRbAgUEj3"
      },
      "outputs": [],
      "source": [
        "# Install Dependencies\n",
        "!pip install --upgrade pip\n",
        "!pip install mediapipe-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-__Po7nUIuH"
      },
      "outputs": [],
      "source": [
        "# Import Dependencies\n",
        "from google.colab import files\n",
        "import os\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from mediapipe_model_maker import gesture_recognizer\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9xY8-YdtabB"
      },
      "source": [
        "Mount your google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3D5_RC6umcq4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtlJMLGmmN7I"
      },
      "source": [
        "Add the path to the zipped folder and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zYVXeeDgYyZU"
      },
      "outputs": [],
      "source": [
        "# path structure: /content/drive/MyDrive/path-to-dataset\n",
        "\n",
        "!unzip /content/drive/MyDrive/...\n",
        "dataset_path = \"Data\" # The name of your folder on the sidebar (<-- left sidebar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5n6R5eQteaV"
      },
      "source": [
        "Print the folders that we have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpO5hWbFY8cm",
        "outputId": "116d3a70-76c8-468e-e559-116cffcd9839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data\n",
            "I\n",
            "L\n",
            "W\n",
            "V\n",
            "E\n",
            "Y\n",
            "R\n",
            "B\n",
            "D\n",
            "K\n",
            "U\n",
            "M\n",
            "A\n",
            "G\n",
            "O\n",
            "Z\n",
            "C\n",
            "N\n",
            "P\n",
            "H\n",
            "J\n",
            "S\n",
            "F\n",
            "Q\n",
            "T\n",
            "None\n",
            "X\n",
            "27\n"
          ]
        }
      ],
      "source": [
        "print(dataset_path)\n",
        "folder_labels = []\n",
        "for i in os.listdir(dataset_path):\n",
        "  print(i)\n",
        "  if os.path.isdir(os.path.join(dataset_path, i)):\n",
        "    folder_labels.append(i)\n",
        "print(len(folder_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbB0jDhqtkwy"
      },
      "source": [
        "Loading the dataset into the gesture recogniser model and splitting the data into sections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEo2L-g8ZW_M",
        "outputId": "9407e0ac-cb04-4f26-b71f-32b21ad40156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using existing files at /tmp/model_maker/gesture_recognizer/palm_detection_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/hand_landmark_full.tflite\n",
            "Using existing files at /tmp/model_maker/gesture_recognizer/gesture_embedder\n"
          ]
        }
      ],
      "source": [
        "# Load dataset into gesture recognizer\n",
        "data = gesture_recognizer.Dataset.from_folder(\n",
        "    dirname=dataset_path,\n",
        "    hparams=gesture_recognizer.HandDataPreprocessingParams()\n",
        ")\n",
        "# Split the data into training and validation sets\n",
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ekk0Wl87tuXW"
      },
      "source": [
        "Setting up the hyperparameters (needs tinkering) and training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOpkaLC6ZeCu"
      },
      "outputs": [],
      "source": [
        "# Set hyperparameters, customizable parameters which affect model accuracy\n",
        "hparams = gesture_recognizer.HParams(learning_rate=0.001, epochs=10, batch_size=32, gamma=0, lr_decay=0.995, shuffle=True, export_dir=\"exported_model\")\n",
        "\n",
        "# Additional ustomizable parameter that affects accuracy\n",
        "model_options = gesture_recognizer.ModelOptions(dropout_rate=0.1, layer_widths=[128, 64])\n",
        "\n",
        "# Gathering these parameters into GestureRecognizerOptions\n",
        "options = gesture_recognizer.GestureRecognizerOptions(model_options=model_options, hparams=hparams)\n",
        "model = gesture_recognizer.GestureRecognizer.create(\n",
        "    train_data=train_data,\n",
        "    validation_data=validation_data,\n",
        "    options=options\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTi1WR1ct3QQ"
      },
      "source": [
        "Evaluating the accuracy and loss of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBe4xlIXdMI9"
      },
      "outputs": [],
      "source": [
        "# loss, acc = model.evaluate(test_data, batch_size=1)\n",
        "# print(f\"Test loss:{loss}, Test accuracy:{acc}\")\n",
        "\n",
        "metric_functions = model._metric_functions + [tf.keras.metrics.F1Score(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
        "model._model.compile(\n",
        "    optimizer=model._optimizer,\n",
        "    loss=model._loss_function,\n",
        "    metrics=metric_functions,\n",
        ")\n",
        "\n",
        "metrics = model.evaluate(test_data)\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Predict on test data\n",
        "predictions = []\n",
        "true_labels = []\n",
        "for ds in test_data.gen_tf_dataset(batch_size=32):\n",
        "    x_batch, y_batch = ds\n",
        "    y_pred = model._model.predict(x_batch)\n",
        "    predictions.extend(np.argmax(y_pred, axis=1))\n",
        "    true_labels.extend(np.argmax(y_batch.numpy(), axis=1))"
      ],
      "metadata": {
        "id": "XqTX9EBcDNPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate and plot confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "# Plot the heatmap using GeeksforGeeks style https://www.geeksforgeeks.org/confusion-matrix-machine-learning/\n",
        "plt.figure(figsize=(20, 18))\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='YlGnBu',\n",
        "            xticklabels=folder_labels, yticklabels=folder_labels)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Normalized Confusion Matrix - Gesture Recognition Model')\n",
        "plt.xticks(rotation=45)\n",
        "plt.yticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# print(\"True labels collected:\", len(true_labels))\n",
        "# print(\"Predictions collected:\", len(predictions))\n",
        "# print(\"Unique true labels:\", np.unique(true_labels))\n",
        "# print(\"Unique predicted labels:\", np.unique(predictions))\n",
        "# print(\"Confusion matrix shape:\", cm.shape)\n",
        "# print(\"Confusion matrix content:\\n\", cm)"
      ],
      "metadata": {
        "id": "JB12oeDGOLRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9qY6hzLt93z"
      },
      "source": [
        "Exporting the model to download a `.task` file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYL2-DJ-hYak"
      },
      "outputs": [],
      "source": [
        "model.export_model()\n",
        "!ls exported_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIJqMpKtuHDt"
      },
      "source": [
        "Saving the model onto your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqWvWkwpLphU"
      },
      "outputs": [],
      "source": [
        "files.download('exported_model/gesture_recognizer.task')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0R8FtoIMhk-"
      },
      "source": [
        "This **removes/deletes** folders. BE CAREFUL WHEN USING THIS BLOCK OF CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qkaOFryHxLUu"
      },
      "outputs": [],
      "source": [
        "# !rm -rf exported_model\n",
        "# !rm -rf Data"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}